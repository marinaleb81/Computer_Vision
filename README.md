# 1. Описание задачи и обоснование подхода

## Описание проблемы и постановка целей

Данный проект направлен на решение задачи бинарной классификации изображений тарелок на две категории: "чистые" (cleaned) и "грязные" (dirty). Эта задача является классическим примером применения компьютерного зрения в практических областях, таких как:
- Автоматизация проверки качества очистки посуды в ресторанах и промышленных кухнях
- Оптимизация работы посудомоечных машин и систем контроля чистоты
- Разработка "умных" бытовых приборов с функцией распознавания состояния посуды

**Основные цели проекта:**
1. Создать высокоточную модель классификации изображений для определения состояния тарелок
2. Достичь максимальной точности классификации на тестовом наборе данных
3. Разработать эффективную стратегию обработки и аугментации изображений для улучшения обобщающей способности модели

## Обоснование выбора методов и инструментов

### Выбор архитектуры модели

В качестве основы для решения задачи был выбран подход с использованием предобученной сверточной нейронной сети **VGG16** с последующей тонкой настройкой (transfer learning и fine-tuning). Обоснование выбора:

1. **Использование предобученной модели** – VGG16, предварительно обученная на ImageNet, обладает мощными возможностями извлечения признаков из изображений. Это позволяет эффективно использовать знания, полученные на миллионах изображений, для нашей более специфической задачи.

2. **Частичная заморозка слоев** – в модели замораживаются все слои, кроме последних нескольких (параметр `unfreeze_layers`), что позволяет:
   - Избежать переобучения на относительно небольшом датасете
   - Сфокусировать обучение на адаптации высокоуровневых признаков к специфике задачи
   - Существенно сократить время обучения

3. **Архитектура надстройки над базовой моделью**:
   - Добавление слоя Flatten для преобразования многомерных выходов сверточной сети в одномерный вектор
   - Включение полносвязного слоя с 256 нейронами для создания пространства признаков, специфичного для нашей задачи. Увеличение нейронов не повлияло на качество работы модели.
   - Применение Dropout (0.5) для предотвращения переобучения
   - Финальный слой с сигмоидной активацией для бинарной классификации

### Стратегия обработки данных и аугментации

Для повышения устойчивости модели к различным вариациям входных данных была разработана комплексная стратегия аугментации, состоящая из двух уровней:

1. **Базовая аугментация с помощью ImageDataGenerator**:
   - Вращение изображений в диапазоне ±15°
   - Сдвиги по вертикали и горизонтали (до 15%)
   - Изменение масштаба (zoom) до 15%
   - Изменение яркости в диапазоне 85-115%
   - Горизонтальные отражения

2. **Кастомная аугментация, специфичная для задачи**:
   - Добавление шума (имитация зернистости изображений при плохом освещении)
   - Случайное размытие (моделирование проблем с фокусировкой)
   - Повышение резкости изображений (улучшение видимости деталей)
   - Регулировка контрастности (адаптация к различным условиям освещения)
   - Симуляция загрязнений (добавление случайных темных точек)

Такой комплексный подход к аугментации позволяет:
- Существенно расширить эффективный размер обучающей выборки
- Повысить устойчивость модели к реальным условиям съемки
- Улучшить способность модели обнаруживать загрязнения различного характера и размера
- Предотвратить переобучение на особенностях конкретных тренировочных изображений

### Выбор гиперпараметров

Основные гиперпараметры модели были выбраны на основе экспериментов и их влияния на качество классификации:

1. **Размер изображения** – увеличен до 512×512 пикселей (с изначальных 224х224), что позволяет сохранить более детальную информацию о мелких загрязнениях на тарелках.

2. **Размер батча** – уменьшен до 1 (с изначальных 2), что обеспечивает более стабильный градиентный спуск и предотвращает переобучение.

3. **Скорость обучения** – установлена на уровне 5e-6, что обеспечивает медленную, но устойчивую сходимость без перепрыгивания локальных минимумов. Пробовала разные варианты скорости, 5e-6 лучший.

4. **Early Stopping** – используется механизм ранней остановки с мониторингом точности и терпением в 10 эпох, что позволяет избежать переобучения.

5. **Dropout** – применяется коэффициент отсева 0.5, что является стандартным балансом между регуляризацией и сохранением полезной информации.

### Выбор библиотек и инструментов

Для реализации проекта использовались следующие основные инструменты:

1. **TensorFlow/Keras** – мощная библиотека для глубокого обучения, обеспечивающая высокоуровневый API для построения и обучения нейронных сетей.

2. **OpenCV (cv2)** – библиотека компьютерного зрения, используемая для реализации методов кастомной аугментации.

3. **NumPy** – библиотека для работы с многомерными массивами, необходимая для эффективной обработки изображений.

4. **Pandas** – библиотека для работы с табличными данными, используемая для создания файла с предсказаниями.

5. **Matplotlib** – библиотека для визуализации данных, используемая для построения графиков обучения и визуализации аугментированных изображений.

Такой набор инструментов обеспечивает гибкость, производительность и удобство разработки при решении задач компьютерного зрения.
